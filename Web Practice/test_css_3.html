<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8">
	<style>
		img {
			border:1px solid red;
			float:right;
		}
	</style>
</head>
<body>
	<img src="https://insujang.github.io/assets/storage_io_stack.png" />
	NVMeDirect Overview

NVMeDirect is a software framework that is used to directly access to a NVMe SSD from a user space application.

In the existing system, applications should access to a storage through several software I/O stacks. storage_io_stack

As the storage media is getting faster, overheads by the software stack takes larger portion of I/O time. Hence, this software I/O stack is being reduced as shown in the above figure. This software I/O stack overheads have been pointed out by several papers. Especially, context switches between user space and kernel space are overwhelming the overhead.

Hence, this paper proposes a direct access from user space applications to NVMe SSD directly via memory-mapped I/O (MMIO). nvmedirect

NVMeDirect Design

nvme_design

There is a NVMeDirect device driver in kernel space that manages queues for user space applications. User space applications use a NVMeDirect library to use I/O queues. As it is mapped to user space, the user applications don’t have to switch its context to kernel space via system calls.

Due to this fundamental design, it does not use virtual file system (VFS) or any other traditional file systems. Current NVMeDirect 1.0 stores raw data, however, NVMeDirect 2.0 supports ForestFS, which is based on ForestDB database.

forestfs

Unfortunately, current public Github repository does not contain ForestFS implementation.

References

NVMeDirect: A User-space I/O Framework for Application-Specific Optimizations on NVMe SSDs
NVMeDirect Slides, HotStorage ‘16
NVMeDirect 2.0, Flash Memory Summit ‘17
 


</body>
</html>